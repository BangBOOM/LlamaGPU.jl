# LlamaGPU.jl

The goal of this project is to inference llama7B and even larger model on GPUs like RTX2080 which does not have enough memory to fit the whole model.
